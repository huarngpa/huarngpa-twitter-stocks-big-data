# Big Data Stack Overview
This is the big data package of the final project. For this part of the stack, I relied on the core technologies we learned about in class (Hadoop, Hive, HBase, Spark), but chose to focus on Spark as the primary point of interface/coordination of the batch, serving, and speed layers.

## Batch Layer
## Serving Layer
## Speed Layer

# Big Data Architecture Considerations

# Technologies Used
* Batch layer
    * Hadoop
    * Hive
    * ORC
    * Spark
    * Stanford CoreNLP
* Serving layer
* Speed layer

# Backend Layer Installation & Deployment
If this is a first time deployment on your cluster, please run the hql contained in the `scripts/create_batch_layer_master_tables.hql`. This builds the tables we for the master dataset.

# Serving Layer Installation & Deployment
# Speed Layer Installation & Deployment
